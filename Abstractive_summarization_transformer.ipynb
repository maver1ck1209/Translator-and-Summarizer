{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d99f6168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fc3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8510ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1464ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
       "      <td>The CBI on Saturday booked four former officia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
       "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
       "      <td>At least three people were killed, including a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has Reliance been barred from trading in f...</td>\n",
       "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was stopped from entering my own studio at Tim...</td>\n",
       "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  4 ex-bank officials booked for cheating bank o...   \n",
       "1     Supreme Court to go paperless in 6 months: CJI   \n",
       "2  At least 3 killed, 30 injured in blast in Sylh...   \n",
       "3  Why has Reliance been barred from trading in f...   \n",
       "4  Was stopped from entering my own studio at Tim...   \n",
       "\n",
       "                                               Short  \n",
       "0  The CBI on Saturday booked four former officia...  \n",
       "1  Chief Justice JS Khehar has said the Supreme C...  \n",
       "2  At least three people were killed, including a...  \n",
       "3  Mukesh Ambani-led Reliance Industries (RIL) wa...  \n",
       "4  TV news anchor Arnab Goswami has said he was t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55ee02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55104, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4944edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = news['Short']\n",
    "summary = news['Headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c76f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('document.pkl','wb') as f:\n",
    "    pickle.dump(document,f)\n",
    "f.close()\n",
    "with open ('summary.pkl','wb') as f:\n",
    "    pickle.dump(summary,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f156207a",
   "metadata": {},
   "source": [
    "### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f217382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <go> 4 ex-bank officials booked for cheating b...\n",
       "1    <go> Supreme Court to go paperless in 6 months...\n",
       "2    <go> At least 3 killed, 30 injured in blast in...\n",
       "3    <go> Why has Reliance been barred from trading...\n",
       "4    <go> Was stopped from entering my own studio a...\n",
       "Name: Headline, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for decoder sequence\n",
    "summary = summary.apply(lambda x: '<go> ' + x + ' <stop>')\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b9a1bc",
   "metadata": {},
   "source": [
    "### TOKENIZING THE TEXTS INTO INTEGER TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18bea39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since < and > from default tokens cannot be removed\n",
    "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
    "oov_token = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd0d7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
    "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9f7a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tokenizer.fit_on_texts(document)\n",
    "summary_tokenizer.fit_on_texts(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "762c106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = document_tokenizer.texts_to_sequences(document)\n",
    "targets = summary_tokenizer.texts_to_sequences(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "195a9a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[184, 22, 12, 71]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_tokenizer.texts_to_sequences([\"This is a test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba32220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is a test']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_tokenizer.sequences_to_texts([[184, 22, 12, 71]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "413f763e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76362, 29661)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
    "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
    "\n",
    "# vocab_size\n",
    "encoder_vocab_size, decoder_vocab_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1013b2e3",
   "metadata": {},
   "source": [
    "### Obtaining insights on lengths for defining maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc61e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_lengths = pd.Series([len(x) for x in document])\n",
    "summary_lengths = pd.Series([len(x) for x in summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cec86e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    55104.000000\n",
       "mean       368.003049\n",
       "std         26.235510\n",
       "min        280.000000\n",
       "25%        350.000000\n",
       "50%        369.000000\n",
       "75%        387.000000\n",
       "max        469.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f0e9982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    55104.000000\n",
       "mean        63.620282\n",
       "std          7.267463\n",
       "min         20.000000\n",
       "25%         59.000000\n",
       "50%         63.000000\n",
       "75%         69.000000\n",
       "max         96.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a23b1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxlen\n",
    "# taking values > and round figured to 75th percentile\n",
    "# at the same time not leaving high variance\n",
    "encoder_maxlen = 400\n",
    "decoder_maxlen = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9fccc",
   "metadata": {},
   "source": [
    "### Padding/Truncating sequences for identical sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e49027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca5f7c",
   "metadata": {},
   "source": [
    "### Creating dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e405bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.cast(inputs, dtype=tf.int32)\n",
    "targets = tf.cast(targets, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e1ae9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c610085",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f5cf2",
   "metadata": {},
   "source": [
    "### Positional Encoding for adding notion of position among words as unlike RNN this is non-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cac9afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(position, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return position * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67b7bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2a631",
   "metadata": {},
   "source": [
    "### Masking\n",
    "Padding mask for masking \"pad\" sequences\n",
    "\n",
    "Lookahead mask for masking future words from contributing in prediction of current words in self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "759feb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "654afb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9917bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb559c84",
   "metadata": {},
   "source": [
    "### Multi-Headed Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56bde9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b59d09",
   "metadata": {},
   "source": [
    "### Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29994ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d5e07",
   "metadata": {},
   "source": [
    "### Fundamental Unit of Transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a49d5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe41e0",
   "metadata": {},
   "source": [
    "### Fundamental Unit of Transformer decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb7fdb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c227788",
   "metadata": {},
   "source": [
    "### Encoder consisting of multiple EncoderLayer(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fffef780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b4436",
   "metadata": {},
   "source": [
    "### Decoder consisting of multiple DecoderLayer(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "040ddef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a10cb0",
   "metadata": {},
   "source": [
    "### Finally, the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ec2a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e0a04",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f437386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-params\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "EPOCHS = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140098c",
   "metadata": {},
   "source": [
    "### Adam optimizer with custom learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5867cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8522d4",
   "metadata": {},
   "source": [
    "### Defining losses and other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23242925",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc2d0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd808ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b0362b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e82aa5",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "277e4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers, \n",
    "    d_model, \n",
    "    num_heads, \n",
    "    dff,\n",
    "    encoder_vocab_size, \n",
    "    decoder_vocab_size, \n",
    "    pe_input=encoder_vocab_size, \n",
    "    pe_target=decoder_vocab_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c3ad4",
   "metadata": {},
   "source": [
    "### Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f371c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c2ce0",
   "metadata": {},
   "source": [
    "### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5be80606",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a62e28",
   "metadata": {},
   "source": [
    "### Training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2131f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            combined_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9aa9129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 10.2978\n",
      "Epoch 1 Batch 429 Loss 9.1925\n",
      "Epoch 1 Batch 858 Loss 8.2378\n",
      "Epoch 1 Loss 8.2349\n",
      "Time taken for 1 epoch: 5649.033754348755 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 7.1024\n",
      "Epoch 2 Batch 429 Loss 6.8037\n",
      "Epoch 2 Batch 858 Loss 6.5971\n",
      "Epoch 2 Loss 6.5960\n",
      "Time taken for 1 epoch: 5531.6381459236145 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 6.4959\n",
      "Epoch 3 Batch 429 Loss 6.0578\n",
      "Epoch 3 Batch 858 Loss 5.9190\n",
      "Epoch 3 Loss 5.9187\n",
      "Time taken for 1 epoch: 5550.726005077362 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 5.6719\n",
      "Epoch 4 Batch 429 Loss 5.5398\n",
      "Epoch 4 Batch 858 Loss 5.4384\n",
      "Epoch 4 Loss 5.4379\n",
      "Time taken for 1 epoch: 5269.15262389183 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 5.2953\n",
      "Epoch 5 Batch 429 Loss 5.1385\n",
      "Epoch 5 Batch 858 Loss 5.0676\n",
      "Saving checkpoint for epoch 5 at checkpoints\\ckpt-1\n",
      "Epoch 5 Loss 5.0674\n",
      "Time taken for 1 epoch: 4943.154168367386 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 4.7678\n",
      "Epoch 6 Batch 429 Loss 4.7619\n",
      "Epoch 6 Batch 858 Loss 4.6918\n",
      "Epoch 6 Loss 4.6913\n",
      "Time taken for 1 epoch: 4955.741745471954 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 4.5976\n",
      "Epoch 7 Batch 429 Loss 4.3984\n",
      "Epoch 7 Batch 858 Loss 4.3496\n",
      "Epoch 7 Loss 4.3494\n",
      "Time taken for 1 epoch: 5013.686643123627 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 4.2951\n",
      "Epoch 8 Batch 429 Loss 4.1019\n",
      "Epoch 8 Batch 858 Loss 4.0678\n",
      "Epoch 8 Loss 4.0677\n",
      "Time taken for 1 epoch: 5022.436611890793 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 3.9645\n",
      "Epoch 9 Batch 429 Loss 3.8464\n",
      "Epoch 9 Batch 858 Loss 3.8367\n",
      "Epoch 9 Loss 3.8367\n",
      "Time taken for 1 epoch: 4998.125368833542 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 3.5522\n",
      "Epoch 10 Batch 429 Loss 3.6540\n",
      "Epoch 10 Batch 858 Loss 3.6568\n",
      "Saving checkpoint for epoch 10 at checkpoints\\ckpt-2\n",
      "Epoch 10 Loss 3.6573\n",
      "Time taken for 1 epoch: 5082.923939228058 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 3.6599\n",
      "Epoch 11 Batch 429 Loss 3.4955\n",
      "Epoch 11 Batch 858 Loss 3.5027\n",
      "Epoch 11 Loss 3.5029\n",
      "Time taken for 1 epoch: 5104.452557563782 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 3.3515\n",
      "Epoch 12 Batch 429 Loss 3.3430\n",
      "Epoch 12 Batch 858 Loss 3.3578\n",
      "Epoch 12 Loss 3.3581\n",
      "Time taken for 1 epoch: 5043.574795007706 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 3.0498\n",
      "Epoch 13 Batch 429 Loss 3.1990\n",
      "Epoch 13 Batch 858 Loss 3.2184\n",
      "Epoch 13 Loss 3.2185\n",
      "Time taken for 1 epoch: 5106.683276414871 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 2.9585\n",
      "Epoch 14 Batch 429 Loss 3.0784\n",
      "Epoch 14 Batch 858 Loss 3.0932\n",
      "Epoch 14 Loss 3.0936\n",
      "Time taken for 1 epoch: 5054.008887290955 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 2.8733\n",
      "Epoch 15 Batch 429 Loss 2.9630\n",
      "Epoch 15 Batch 858 Loss 2.9823\n",
      "Saving checkpoint for epoch 15 at checkpoints\\ckpt-3\n",
      "Epoch 15 Loss 2.9827\n",
      "Time taken for 1 epoch: 5104.063579797745 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 2.9384\n",
      "Epoch 16 Batch 429 Loss 2.8538\n",
      "Epoch 16 Batch 858 Loss 2.8798\n",
      "Epoch 16 Loss 2.8798\n",
      "Time taken for 1 epoch: 5098.555980920792 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 2.7048\n",
      "Epoch 17 Batch 429 Loss 2.7599\n",
      "Epoch 17 Batch 858 Loss 2.7820\n",
      "Epoch 17 Loss 2.7823\n",
      "Time taken for 1 epoch: 5042.633774280548 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 2.4958\n",
      "Epoch 18 Batch 429 Loss 2.6609\n",
      "Epoch 18 Batch 858 Loss 2.7000\n",
      "Epoch 18 Loss 2.7002\n",
      "Time taken for 1 epoch: 5132.5007293224335 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 2.7500\n",
      "Epoch 19 Batch 429 Loss 2.5862\n",
      "Epoch 19 Batch 858 Loss 2.6227\n",
      "Epoch 19 Loss 2.6232\n",
      "Time taken for 1 epoch: 8822.625334501266 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 2.4354\n",
      "Epoch 20 Batch 429 Loss 2.5053\n",
      "Epoch 20 Batch 858 Loss 2.5494\n",
      "Saving checkpoint for epoch 20 at checkpoints\\ckpt-4\n",
      "Epoch 20 Loss 2.5498\n",
      "Time taken for 1 epoch: 7550.260479211807 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 2.4583\n",
      "Epoch 21 Batch 429 Loss 2.4466\n",
      "Epoch 21 Batch 858 Loss 2.4816\n",
      "Epoch 21 Loss 2.4819\n",
      "Time taken for 1 epoch: 7413.457948684692 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 2.3063\n",
      "Epoch 22 Batch 429 Loss 2.3837\n",
      "Epoch 22 Batch 858 Loss 2.4245\n",
      "Epoch 22 Loss 2.4249\n",
      "Time taken for 1 epoch: 7386.6674036979675 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 2.2432\n",
      "Epoch 23 Batch 429 Loss 2.3213\n",
      "Epoch 23 Batch 858 Loss 2.3618\n",
      "Epoch 23 Loss 2.3626\n",
      "Time taken for 1 epoch: 7382.078800678253 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        train_step(inp, tar)\n",
    "    \n",
    "        # 55k samples\n",
    "        # we display 3 batch results -- 0th, middle and last one (approx)\n",
    "        # 55k / 64 ~ 858; 858 / 2 = 429\n",
    "        if batch % 429 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
    "      \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93605783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_document):\n",
    "    input_document = document_tokenizer.texts_to_sequences([input_document])\n",
    "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "\n",
    "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
    "\n",
    "    decoder_input = [summary_tokenizer.word_index[\"<go>\"]]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(decoder_maxlen):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input, \n",
    "            output,\n",
    "            False,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predictions = predictions[: ,-1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        if predicted_id == summary_tokenizer.word_index[\"<stop>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "564be473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(input_document):\n",
    "    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
    "    summarized = evaluate(input_document=input_document)[0].numpy()\n",
    "    summarized = np.expand_dims(summarized[1:], 0)  # not printing <go> token\n",
    "    return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1d442cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two more expensive than air force for sale in 2017'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\n",
    "    \"The popular models Under 3 Lakh are Maruti Wagon R (Rs. 2 Lakh - 3 Lakh), Volkswagen Polo (Rs. 2 Lakh - 3 Lakh), Renault KWID (Rs. 2 Lakh - 3 Lakh), Hyundai i20 (Rs. 2 Lakh - 3 Lakh), Chevrolet Sail (Rs. 2 Lakh - 2.60 Lakh) in New Delhi.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7ff41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46dd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
